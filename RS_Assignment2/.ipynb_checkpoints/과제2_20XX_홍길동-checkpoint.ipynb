{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2: Movie recommendation\n",
    "\n",
    "- 과제 목표: 뉴럴 네트워크 모델을 설계한 후 모델을 학습하여 각 영화들의 embedding 들을 생성하고, 영화 embedding 을 활용하여 각 사용자에게 맞춤형 영화를 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice\n",
    "\n",
    "<br>\n",
    "\n",
    "- 과제를 수행하면서 각 task 마다 꼭 주어진 1개의 cell만을 사용할 필요는 없으며, 여러 개의 cell을 추가하여 자유롭게 사용해도 괜찮습니다.\n",
    "- 과제 수행을 위해 필요한 module이 있다면 추가로 import 해도 괜찮습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.11.0-cp39-none-macosx_10_9_x86_64.whl (129.9 MB)\n",
      "\u001b[K     |█████▍                          | 21.9 MB 67 kB/s eta 0:26:430"
     ]
    }
   ],
   "source": [
    "! pip install sklearn\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fs/qj1gfd190kn3rh_9tb9rhbn80000gn/T/ipykernel_50724/3283390087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;31m# For building network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch # For building network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import permutations\n",
    "from itertools import permutations # For making pairs\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './MovieLens100K/'\n",
    "df_ratings = pd.read_csv(dir + 'ratings.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "df_movies = pd.read_csv(dir + 'movies.csv', usecols=['movieId', 'title', 'genres']) # for title-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 1 (3 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "1. df_ratings로 부터 각 사용자들이 본 영화를 기록.\n",
    "2. 사용자 마다 본 영화 목록을 $(movie1, movie2)$, $(movie2, movie1)$ 과 같이 pair로 생성.\n",
    "    - 즉, 각 사용자 마다 본 영화 목록에 대해 Permutation을 수행\n",
    "3. 2번 과정이 끝난 후, random을 이용해 각 pair 순서를 무작위로 shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1882, 6), (115713, 61240), (2000, 5952), (2011, 2053), (48780, 8641), (1466, 1093), (4011, 26444), (1, 161), (1994, 68205), (3249, 1240), (7, 4654), (6874, 62374), (608, 7396)]\n",
      "2294190\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "df_users = df_ratings['userId'].drop_duplicates()\n",
    "movies_permutation_result = []\n",
    "cnt = 0\n",
    "for i in df_users:\n",
    "    if(cnt == 50):\n",
    "        break\n",
    "    is_user_movies = df_ratings['userId'] == i\n",
    "    user_movies = df_ratings[is_user_movies]['movieId']\n",
    "    user_movies_list = user_movies.values.tolist()\n",
    "    user_movies_permutation = list(permutations(user_movies_list, 2))\n",
    "    movies_permutation_result.extend(user_movies_permutation)\n",
    "    cnt += 1\n",
    "random.shuffle(movies_permutation_result)\n",
    "# print(len(movies_permutation_result))\n",
    "print(movies_permutation_result[0:13])\n",
    "print(len(movies_permutation_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train neural networks for generating movie embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 2 (4 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 각 영화 임베딩을 구하기 위해 뉴럴 네트워크 모델을 활용하여 multi-class classification 을 수행\n",
    "\n",
    "- 설계할 신경망의 기본 구조는 **Input Layer - Hidden(Embedding) Layer - Output Layer**.\n",
    "    - 7주차 강의자료 p.7 신경망 구조 이미지 참고\n",
    "\n",
    "- 현재 Network를 통해 하고자 하는 task는 multi-class classification.\n",
    "    - 예: $(movie1, movie2)$ 와 같은 입력 데이터와 정답 출력 데이터를 이용해 모델을 학습\n",
    "        - Input : $movie1$의 one-hot vector\n",
    "        - Output : $\\widehat{movie2}$의 one-hot vector\n",
    "        - Compute Loss : $\\widehat{movie2}$ 와 $movie2$ 간의 Cross-entropy Loss\n",
    "- 학습이 완료된 이후에 input layer와 hidden(embedding) layer 사이의 weight matrix $W_{in}$를 movie에 대한 embedding vector로 사용이 가능.\n",
    "> embedding size(# of hidden units)는 100 이하로 두는 것을 권장. <br>\n",
    "> embedding layer 다음 hidden layer를 더 추가하여 Genre와 같은 추가 정보를 학습에 활용 할 수도 있음 (필수적으로 고려해야할 사항은 아님).\n",
    "\n",
    "- 설계한 뉴럴 네트워크 모델의 학습이 완료된 후, 학습된 weight matrix $W_{in}$의 행/열벡터를 각 영화에 대한 embedding vector로 간주하여 영화 embedding 들을 구할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Code Here\n",
    "movies_pair_dataframe = pd.DataFrame(data= movies_permutation_result, columns=['movie1','movie2'])\n",
    "# movie_one_array = movies_pair_dataframe['movie1'].to_numpy()\n",
    "# movie_two_array = movies_pair_dataframe['movie2'].to_numpy()\n",
    "# print(type(movie_one_array))\n",
    "# 임베딩 처리\n",
    "labels_one = movies_pair_dataframe['movie1'].values.reshape(-1,1)\n",
    "labels_two = movies_pair_dataframe['movie2'].values.reshape(-1,1)\n",
    "ohe = OneHotEncoder()\n",
    "ohe2 = OneHotEncoder()\n",
    "ohe.fit(labels_one)\n",
    "ohe_labels =ohe.transform(labels_one)\n",
    "ohe2.fit(labels_two)\n",
    "ohe2_labels = ohe2.transform(labels_two)\n",
    "\n",
    "print(\"hihi\")\n",
    "#여기서부터 학습 시키자\n",
    "\n",
    "# layer = nn.Linear(in_features=ohe_labels.shape[0]*ohe_labels.shape[1], out_features=100)\n",
    "model = nn.Linear(in_features=ohe_labels.shape[0]*ohe_labels.shape[1],out_features=100)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "nb_epochs = 10\n",
    "print(\"epochs\")\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hidden = model(ohe_labels)\n",
    "    output_model = nn.Linear(in_features=100, out_features=ohe_labels.shape[0]*ohe_labels.shape[1])\n",
    "    prediction = model(output_model)\n",
    "    cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "    cost = cross_entropy_loss(output_model, ohe2_labels)\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward() # backward 연산\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "    if epoch % 1 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend customized movies to user\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 3 (3 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 임의의 한명의 사용자에 대하여 해당 사용자가 봤던 영화 n개에 대해 **통합된 embedding vector**를 생성.\n",
    "    - n개의 embedding vector들에 대해, element-wise한 계산을 통해 통합된 하나의 embedding vector를 생성.\n",
    "    - 이 embedding vector는 해당 사용자의 전반적인 영화 시청 성향을 나타내는 embedding vector로 간주할 수 있음.\n",
    "    - 즉, **사용자 1명 당 1개의 embedding vector**를 가짐.\n",
    "- 통합된 embedding vector와 학습된 weight matrix $W_{in}$의 모든 영화 embedding vector들 간의 유사도를 계산.\n",
    "- 그 중 유사도가 높은 (top n) 영화들을 선정, 사용자에게 추천.\n",
    "    > Recommended format : MovieId, Title, Genre, Similarity 가 포함된 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Code Here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
