{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2: Movie recommendation\n",
    "\n",
    "- 과제 목표: 뉴럴 네트워크 모델을 설계한 후 모델을 학습하여 각 영화들의 embedding 들을 생성하고, 영화 embedding 을 활용하여 각 사용자에게 맞춤형 영화를 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice\n",
    "\n",
    "<br>\n",
    "\n",
    "- 과제를 수행하면서 각 task 마다 꼭 주어진 1개의 cell만을 사용할 필요는 없으며, 여러 개의 cell을 추가하여 자유롭게 사용해도 괜찮습니다.\n",
    "- 과제 수행을 위해 필요한 module이 있다면 추가로 import 해도 괜찮습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch # For building network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import permutations\n",
    "from itertools import permutations # For making pairs\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vidigummy/opt/anaconda3/envs/RS/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './MovieLens100K/'\n",
    "df_ratings = pd.read_csv(dir + 'ratings.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "df_movies_real = pd.read_csv(dir + 'movies.csv', usecols=['movieId', 'title', 'genres']) # for title-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 1 (3 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "1. df_ratings로 부터 각 사용자들이 본 영화를 기록.\n",
    "2. 사용자 마다 본 영화 목록을 $(movie1, movie2)$, $(movie2, movie1)$ 과 같이 pair로 생성.\n",
    "    - 즉, 각 사용자 마다 본 영화 목록에 대해 Permutation을 수행\n",
    "3. 2번 과정이 끝난 후, random을 이용해 각 pair 순서를 무작위로 shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating\n",
      "0           1        1     4.0\n",
      "1           1        3     4.0\n",
      "2           1        6     4.0\n",
      "3           1       47     5.0\n",
      "4           1       50     5.0\n",
      "...       ...      ...     ...\n",
      "99590     610      912     3.5\n",
      "99591     610      919     3.5\n",
      "99592     610      923     4.0\n",
      "99593     610      924     4.5\n",
      "99594     610      968     4.0\n",
      "\n",
      "[21667 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "df_users = df_ratings['userId'].drop_duplicates()\n",
    "movies_permutation_result = []\n",
    "df_movies = df_ratings['movieId'] < 1000\n",
    "df_movies_true = df_ratings[df_movies]\n",
    "print(df_movies_true)\n",
    "for i in df_users:\n",
    "    is_user_movies = df_movies_true['userId'] == i\n",
    "    user_movies = df_movies_true[is_user_movies]['movieId']\n",
    "    user_movies_list = user_movies.values.tolist()\n",
    "    user_movies_permutation = list(permutations(user_movies_list, 2))\n",
    "    movies_permutation_result.extend(user_movies_permutation)\n",
    "random.shuffle(movies_permutation_result)\n",
    "# print(len(movies_permutation_result))\n",
    "# print(movies_permutation_result)\n",
    "# print(len(movies_permutation_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train neural networks for generating movie embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 2 (4 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 각 영화 임베딩을 구하기 위해 뉴럴 네트워크 모델을 활용하여 multi-class classification 을 수행\n",
    "\n",
    "- 설계할 신경망의 기본 구조는 **Input Layer - Hidden(Embedding) Layer - Output Layer**.\n",
    "    - 7주차 강의자료 p.7 신경망 구조 이미지 참고\n",
    "\n",
    "- 현재 Network를 통해 하고자 하는 task는 multi-class classification.\n",
    "    - 예: $(movie1, movie2)$ 와 같은 입력 데이터와 정답 출력 데이터를 이용해 모델을 학습\n",
    "        - Input : $movie1$의 one-hot vector\n",
    "        - Output : $\\widehat{movie2}$의 one-hot vector\n",
    "        - Compute Loss : $\\widehat{movie2}$ 와 $movie2$ 간의 Cross-entropy Loss\n",
    "- 학습이 완료된 이후에 input layer와 hidden(embedding) layer 사이의 weight matrix $W_{in}$를 movie에 대한 embedding vector로 사용이 가능.\n",
    "> embedding size(# of hidden units)는 100 이하로 두는 것을 권장. <br>\n",
    "> embedding layer 다음 hidden layer를 더 추가하여 Genre와 같은 추가 정보를 학습에 활용 할 수도 있음 (필수적으로 고려해야할 사항은 아님).\n",
    "\n",
    "- 설계한 뉴럴 네트워크 모델의 학습이 완료된 후, 학습된 weight matrix $W_{in}$의 행/열벡터를 각 영화에 대한 embedding vector로 간주하여 영화 embedding 들을 구할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.embedded_layer = nn.Linear(input_size, 100)\n",
    "        self.hidden_layer = nn.Linear(100, 100)\n",
    "        self.output_layer = nn.Linear(100,input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x = self.embedded_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         movieId\n",
      "0            155\n",
      "1             72\n",
      "2            553\n",
      "3            508\n",
      "4            775\n",
      "...          ...\n",
      "1869541      920\n",
      "1869542      741\n",
      "1869543      587\n",
      "1869544      329\n",
      "1869545      973\n",
      "\n",
      "[1869546 rows x 1 columns]\n",
      "torch_one_hot_movie1 shape :  torch.Size([1869546, 761])\n",
      "Epoch    1/2 loss: 6.635469\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "movies_pair_dataframe = pd.DataFrame(data= movies_permutation_result, columns=['movie1','movie2'])\n",
    "\n",
    "#영화의 개수를 가지고 one-hot vector로 만들어뿌자\n",
    "df_movie1 = pd.DataFrame(data=movies_pair_dataframe['movie1'].values,columns=['movieId'])\n",
    "print(df_movie1)\n",
    "df_movie2 = pd.DataFrame(data=movies_pair_dataframe['movie2'].values,columns=['movieId'])\n",
    "df_concat_movies = pd.concat([df_movie1,df_movie2],axis=0)\n",
    "df_one_hot_embedded = pd.get_dummies(data=df_concat_movies, columns = ['movieId'])\n",
    "df_one_hot_embedded_movie1 = df_one_hot_embedded.iloc[:int(df_one_hot_embedded.shape[0]/2), :]\n",
    "df_one_hot_embedded_movie2 = df_one_hot_embedded.iloc[int(df_one_hot_embedded.shape[0]/2):,:]\n",
    "#df로 만들었다. (1099200, 1859)로 자식들이 아주 건강하다.\n",
    "torch_one_hot_movie1 = torch.as_tensor(df_one_hot_embedded_movie1.values).float()\n",
    "torch_one_hot_movie2 = torch.as_tensor(df_one_hot_embedded_movie2.values).float()\n",
    "print(\"torch_one_hot_movie1 shape : \", torch_one_hot_movie1.shape)\n",
    "model = NnNetwork(torch_one_hot_movie1.shape[1])\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "# optimizer2 = torch.optim.Adam(model.parameters(),lr=0.1, betas = (0.9,0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer2 = torch.optim.Adam(model.parameters(),lr=0.1, betas = (0.9,0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "for epoch in range(2):\n",
    "    #make one-hot vector(input, target Generation)\n",
    "    output = model(torch_one_hot_movie1)\n",
    "    loss = loss_function(output, torch_one_hot_movie2)\n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "    # loss.backward()\n",
    "    print('Epoch {:4d}/{} loss: {:.6f}'.format(\n",
    "        epoch+1, 2, loss.item()\n",
    "    ))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n",
      "100\n",
      "364\n",
      "57\n",
      "474\n",
      "454\n",
      "485\n",
      "521\n",
      "1\n",
      "141\n",
      "810\n",
      "318\n",
      "257\n",
      "719\n",
      "158\n",
      "590\n",
      "426\n",
      "805\n",
      "608\n",
      "558\n",
      "1\n",
      "302\n",
      "704\n",
      "903\n",
      "569\n",
      "912\n",
      "223\n",
      "47\n",
      "802\n",
      "780\n",
      "736\n",
      "800\n",
      "780\n",
      "942\n",
      "342\n",
      "930\n",
      "158\n",
      "367\n",
      "529\n",
      "18\n",
      "172\n",
      "838\n",
      "592\n",
      "924\n",
      "24\n",
      "661\n",
      "303\n",
      "198\n",
      "915\n",
      "23\n",
      "788\n",
      "367\n",
      "231\n",
      "260\n",
      "32\n",
      "344\n",
      "145\n",
      "207\n",
      "296\n",
      "317\n",
      "719\n",
      "318\n",
      "736\n",
      "183\n",
      "926\n",
      "281\n",
      "288\n",
      "11\n",
      "216\n",
      "307\n",
      "231\n",
      "203\n",
      "34\n",
      "673\n",
      "315\n",
      "356\n",
      "87\n",
      "34\n",
      "589\n",
      "667\n",
      "588\n",
      "75\n",
      "648\n",
      "110\n",
      "223\n",
      "457\n",
      "457\n",
      "224\n",
      "538\n",
      "535\n",
      "490\n",
      "160\n",
      "225\n",
      "595\n",
      "261\n",
      "329\n",
      "296\n",
      "491\n",
      "260\n",
      "656\n",
      "356\n",
      "302\n",
      "475\n",
      "475\n",
      "635\n",
      "356\n",
      "47\n",
      "529\n",
      "372\n",
      "538\n",
      "89\n",
      "552\n",
      "410\n",
      "896\n",
      "968\n",
      "367\n",
      "317\n",
      "112\n",
      "339\n",
      "300\n",
      "231\n",
      "412\n",
      "707\n",
      "41\n",
      "969\n",
      "58\n",
      "150\n",
      "414\n",
      "711\n",
      "32\n",
      "73\n",
      "474\n",
      "317\n",
      "945\n",
      "374\n",
      "316\n",
      "173\n",
      "95\n",
      "952\n",
      "377\n",
      "242\n",
      "953\n",
      "168\n",
      "432\n",
      "16\n",
      "349\n",
      "838\n",
      "362\n",
      "616\n",
      "528\n",
      "223\n",
      "608\n",
      "110\n",
      "150\n",
      "34\n",
      "858\n",
      "252\n",
      "296\n",
      "507\n",
      "553\n",
      "553\n",
      "22\n",
      "617\n",
      "222\n",
      "173\n",
      "266\n",
      "160\n",
      "493\n",
      "95\n",
      "628\n",
      "529\n",
      "111\n",
      "380\n",
      "587\n",
      "253\n",
      "932\n",
      "534\n",
      "208\n",
      "879\n",
      "57\n",
      "168\n",
      "173\n",
      "1\n",
      "16\n",
      "527\n",
      "367\n",
      "926\n",
      "105\n",
      "491\n",
      "355\n",
      "44\n",
      "186\n",
      "231\n",
      "357\n",
      "92\n",
      "168\n",
      "541\n",
      "433\n",
      "647\n",
      "47\n",
      "903\n",
      "317\n",
      "110\n",
      "66\n",
      "968\n",
      "70\n",
      "551\n",
      "45\n",
      "325\n",
      "380\n",
      "279\n",
      "393\n",
      "520\n",
      "605\n",
      "832\n",
      "635\n",
      "585\n",
      "965\n",
      "318\n",
      "909\n",
      "736\n",
      "65\n",
      "198\n",
      "440\n",
      "158\n",
      "380\n",
      "292\n",
      "79\n",
      "409\n",
      "364\n",
      "761\n",
      "788\n",
      "922\n",
      "247\n",
      "903\n",
      "802\n",
      "82\n",
      "5\n",
      "293\n",
      "353\n",
      "288\n",
      "261\n",
      "145\n",
      "479\n",
      "574\n",
      "17\n",
      "508\n",
      "781\n",
      "39\n",
      "110\n",
      "897\n",
      "296\n",
      "520\n",
      "947\n",
      "564\n",
      "954\n",
      "517\n",
      "160\n",
      "10\n",
      "318\n",
      "593\n",
      "208\n",
      "648\n",
      "224\n",
      "546\n",
      "589\n",
      "527\n",
      "608\n",
      "648\n",
      "434\n",
      "1\n",
      "552\n",
      "175\n",
      "592\n",
      "431\n",
      "318\n",
      "851\n",
      "92\n",
      "208\n",
      "223\n",
      "367\n",
      "736\n",
      "508\n",
      "338\n",
      "296\n",
      "150\n",
      "910\n",
      "955\n",
      "150\n",
      "635\n",
      "688\n",
      "370\n",
      "708\n",
      "350\n",
      "949\n",
      "904\n",
      "11\n",
      "216\n",
      "3\n",
      "648\n",
      "21\n",
      "204\n",
      "592\n",
      "364\n",
      "185\n",
      "31\n",
      "232\n",
      "733\n",
      "455\n",
      "39\n",
      "296\n",
      "919\n",
      "762\n",
      "784\n",
      "23\n",
      "230\n",
      "150\n",
      "837\n",
      "589\n",
      "101\n",
      "62\n",
      "107\n",
      "333\n",
      "839\n",
      "908\n",
      "590\n",
      "50\n",
      "15\n",
      "383\n",
      "457\n",
      "10\n",
      "379\n",
      "902\n",
      "928\n",
      "551\n",
      "259\n",
      "357\n",
      "47\n",
      "930\n",
      "585\n",
      "94\n",
      "531\n",
      "367\n",
      "173\n",
      "349\n",
      "296\n",
      "318\n",
      "224\n",
      "46\n",
      "903\n",
      "377\n",
      "26\n",
      "172\n",
      "736\n",
      "50\n",
      "367\n",
      "70\n",
      "203\n",
      "432\n",
      "7\n",
      "231\n",
      "494\n",
      "100\n",
      "521\n",
      "11\n",
      "160\n",
      "429\n",
      "941\n",
      "594\n",
      "412\n",
      "177\n",
      "454\n",
      "198\n",
      "442\n",
      "480\n",
      "590\n",
      "531\n",
      "551\n",
      "907\n",
      "661\n",
      "351\n",
      "173\n",
      "852\n",
      "32\n",
      "737\n",
      "364\n",
      "227\n",
      "153\n",
      "973\n",
      "5\n",
      "424\n",
      "916\n",
      "303\n",
      "377\n",
      "355\n",
      "605\n",
      "223\n",
      "52\n",
      "158\n",
      "316\n",
      "762\n",
      "940\n",
      "537\n",
      "288\n",
      "539\n",
      "173\n",
      "879\n",
      "893\n",
      "173\n",
      "783\n",
      "282\n",
      "371\n",
      "333\n",
      "290\n",
      "172\n",
      "474\n",
      "316\n",
      "432\n",
      "593\n",
      "2\n",
      "346\n",
      "382\n",
      "735\n",
      "457\n",
      "908\n",
      "1\n",
      "111\n",
      "924\n",
      "34\n",
      "590\n",
      "551\n",
      "296\n",
      "380\n",
      "173\n",
      "858\n",
      "750\n",
      "653\n",
      "848\n",
      "135\n",
      "47\n",
      "475\n",
      "29\n",
      "357\n",
      "719\n",
      "608\n",
      "924\n",
      "455\n",
      "491\n",
      "151\n",
      "586\n",
      "111\n",
      "293\n",
      "586\n",
      "204\n",
      "21\n",
      "340\n",
      "272\n",
      "123\n",
      "442\n",
      "515\n",
      "199\n",
      "500\n",
      "105\n",
      "537\n",
      "36\n",
      "948\n",
      "587\n",
      "608\n",
      "866\n",
      "342\n",
      "26\n",
      "229\n",
      "213\n",
      "64\n",
      "913\n",
      "588\n",
      "708\n",
      "186\n",
      "552\n",
      "540\n",
      "158\n",
      "674\n",
      "500\n",
      "280\n",
      "736\n",
      "17\n",
      "6\n",
      "457\n",
      "803\n",
      "58\n",
      "339\n",
      "17\n",
      "539\n",
      "548\n",
      "736\n",
      "185\n",
      "784\n",
      "176\n",
      "908\n",
      "480\n",
      "17\n",
      "492\n",
      "327\n",
      "260\n",
      "252\n",
      "347\n",
      "65\n",
      "781\n",
      "316\n",
      "434\n",
      "50\n",
      "994\n",
      "282\n",
      "296\n",
      "198\n",
      "421\n",
      "165\n",
      "104\n",
      "916\n",
      "315\n",
      "34\n",
      "588\n",
      "529\n",
      "788\n",
      "153\n",
      "168\n",
      "610\n",
      "520\n",
      "260\n",
      "296\n",
      "353\n",
      "282\n",
      "367\n",
      "19\n",
      "420\n",
      "948\n",
      "432\n",
      "29\n",
      "156\n",
      "733\n",
      "357\n",
      "247\n",
      "780\n",
      "208\n",
      "318\n",
      "253\n",
      "223\n",
      "344\n",
      "296\n",
      "434\n",
      "741\n",
      "290\n",
      "47\n",
      "596\n",
      "2\n",
      "17\n",
      "282\n",
      "223\n",
      "344\n",
      "950\n",
      "5\n",
      "590\n",
      "899\n",
      "246\n",
      "946\n",
      "47\n",
      "18\n",
      "380\n",
      "343\n",
      "315\n",
      "185\n",
      "173\n",
      "575\n",
      "798\n",
      "765\n",
      "43\n",
      "339\n",
      "110\n",
      "836\n",
      "31\n",
      "337\n",
      "95\n",
      "21\n",
      "923\n",
      "158\n",
      "762\n",
      "348\n",
      "788\n",
      "457\n",
      "314\n",
      "912\n",
      "337\n",
      "608\n",
      "343\n",
      "62\n",
      "353\n",
      "361\n",
      "480\n",
      "836\n",
      "173\n",
      "480\n",
      "349\n",
      "111\n",
      "239\n",
      "903\n",
      "175\n",
      "361\n",
      "647\n",
      "438\n",
      "516\n",
      "246\n",
      "736\n",
      "892\n",
      "736\n",
      "315\n",
      "608\n",
      "45\n",
      "354\n",
      "885\n",
      "376\n",
      "2\n",
      "592\n",
      "179\n",
      "237\n",
      "736\n",
      "485\n",
      "17\n",
      "421\n",
      "168\n",
      "588\n",
      "95\n",
      "708\n",
      "923\n",
      "931\n",
      "440\n",
      "661\n",
      "453\n",
      "367\n",
      "34\n",
      "733\n",
      "145\n",
      "608\n",
      "480\n",
      "415\n",
      "786\n",
      "555\n",
      "26\n",
      "780\n",
      "150\n",
      "597\n",
      "440\n",
      "319\n",
      "922\n",
      "2\n",
      "923\n",
      "231\n",
      "2\n",
      "235\n",
      "348\n",
      "432\n",
      "292\n",
      "458\n",
      "708\n",
      "39\n",
      "338\n",
      "36\n",
      "47\n",
      "762\n",
      "296\n",
      "586\n",
      "733\n",
      "466\n",
      "313\n",
      "628\n",
      "589\n",
      "434\n",
      "585\n",
      "34\n",
      "804\n",
      "535\n",
      "95\n",
      "551\n",
      "673\n",
      "533\n",
      "543\n",
      "743\n",
      "440\n",
      "968\n",
      "466\n",
      "112\n",
      "141\n",
      "594\n",
      "904\n",
      "714\n",
      "329\n",
      "780\n",
      "410\n",
      "440\n",
      "597\n",
      "719\n",
      "3\n",
      "168\n",
      "750\n",
      "628\n",
      "485\n",
      "165\n",
      "780\n",
      "520\n",
      "648\n",
      "300\n",
      "648\n",
      "524\n",
      "852\n",
      "514\n",
      "140\n",
      "376\n",
      "367\n",
      "185\n",
      "475\n",
      "541\n",
      "318\n",
      "708\n",
      "780\n",
      "500\n",
      "380\n",
      "928\n",
      "587\n",
      "597\n",
      "500\n",
      "543\n",
      "180\n",
      "62\n",
      "110\n",
      "2\n",
      "50\n",
      "81\n",
      "292\n",
      "491\n",
      "282\n",
      "355\n",
      "361\n",
      "535\n",
      "493\n",
      "593\n",
      "288\n",
      "708\n",
      "328\n",
      "52\n",
      "709\n",
      "473\n",
      "339\n",
      "176\n",
      "230\n",
      "260\n",
      "208\n",
      "509\n",
      "898\n",
      "742\n",
      "928\n",
      "160\n",
      "597\n",
      "830\n",
      "316\n",
      "354\n"
     ]
    }
   ],
   "source": [
    "movie_embedding = dict()\n",
    "cnt = 0\n",
    "# print(df_movie1)\n",
    "#761*100\n",
    "for param in model.named_parameters():\n",
    "    a = param[1]\n",
    "    print(len(a[0]))\n",
    "    print(len(a))\n",
    "    for i in range(len(a[0])):\n",
    "        # print(i)\n",
    "        # if(int(df_movie1.loc[i,'movieId']) == 70):\n",
    "        #     print(70)\n",
    "        print(int(df_movie1.loc[i,'movieId']))\n",
    "        movie_embedding[int(df_movie1.loc[i,'movieId'])] = a[:,i]\n",
    "    break\n",
    "print(len(movie_embedding))\n",
    "# print(movie_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend customized movies to user\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 3 (3 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 임의의 한명의 사용자에 대하여 해당 사용자가 봤던 영화 n개에 대해 **통합된 embedding vector**를 생성.\n",
    "    - n개의 embedding vector들에 대해, element-wise한 계산을 통해 통합된 하나의 embedding vector를 생성.\n",
    "    - 이 embedding vector는 해당 사용자의 전반적인 영화 시청 성향을 나타내는 embedding vector로 간주할 수 있음.\n",
    "    - 즉, **사용자 1명 당 1개의 embedding vector**를 가짐.\n",
    "- 통합된 embedding vector와 학습된 weight matrix $W_{in}$의 모든 영화 embedding vector들 간의 유사도를 계산.\n",
    "- 그 중 유사도가 높은 (top n) 영화들을 선정, 사용자에게 추천.\n",
    "    > Recommended format : MovieId, Title, Genre, Similarity 가 포함된 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157  has lost!\n",
      "163  has lost!\n",
      "423  has lost!\n",
      "441  has lost!\n",
      "943  has lost!\n",
      "44\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([ 0.0967, -0.0617,  0.0765, -0.0654, -0.0136, -0.0791, -0.0399,  0.0945,\n",
      "         0.0942, -0.0122,  0.0873, -0.0109, -0.0040, -0.0312, -0.1105,  0.1167,\n",
      "         0.1140, -0.0076,  0.0039,  0.0717,  0.1102, -0.0535,  0.0680,  0.0670,\n",
      "         0.0834, -0.0064, -0.0597,  0.0823,  0.1260, -0.0479, -0.1035, -0.0413,\n",
      "        -0.0071,  0.0853,  0.0965, -0.0903,  0.1218,  0.0788, -0.0795,  0.0931,\n",
      "         0.0767,  0.1232,  0.0723,  0.1404, -0.0098, -0.0414,  0.0743,  0.0905,\n",
      "        -0.0631,  0.0785, -0.0497,  0.0789, -0.0311, -0.0569,  0.0782,  0.0861,\n",
      "        -0.0760,  0.1213, -0.0836,  0.0959, -0.1193,  0.0983, -0.1215, -0.0650,\n",
      "         0.0976, -0.0315,  0.0828, -0.0041, -0.0952, -0.0386,  0.0014, -0.0178,\n",
      "         0.0065, -0.0388,  0.1193,  0.0904,  0.1477,  0.0017, -0.0982, -0.0712,\n",
      "         0.1067,  0.0850, -0.0838,  0.1082, -0.0280,  0.0779,  0.1138,  0.0843,\n",
      "         0.0728,  0.0833, -0.0040, -0.0244,  0.1217,  0.0948,  0.0928, -0.0018,\n",
      "        -0.0047,  0.0595, -0.0485, -0.0666], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "is_user_movies = df_movies_true['userId'] == 1\n",
    "users_movies = df_movies_true[is_user_movies]\n",
    "user_movies = users_movies['movieId']\n",
    "# print(user_movies.shape)\n",
    "user_movie_dict =dict()\n",
    "# print(df_movie1[df_movie1['movieId'] == 157])\n",
    "# for movie in movie_embedding:\n",
    "#     print(movie)\n",
    "for movieId in user_movies:\n",
    "    # print(movie_embedding[movieId])\n",
    "    try:\n",
    "        user_movie_dict[movieId] = movie_embedding[movieId]\n",
    "    except:\n",
    "        print(movieId , \" has lost!\")\n",
    "# print(user_movie_dict)\n",
    "print(len(user_movie_dict))\n",
    "user_embedding_vector = torch.zeros(100)\n",
    "print(user_embedding_vector)\n",
    "for i in user_movie_dict.keys():\n",
    "    # print(len(i_list))\n",
    "    i_list = user_movie_dict[i]/len(user_movie_dict)\n",
    "    for j in range(0,len(i_list)):\n",
    "        user_embedding_vector[j] += i_list[j]\n",
    "\n",
    "#유저 임베딩 벡터 완성(이게 맞나...)\n",
    "print(user_embedding_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId :  942  | title :  Laura (1944) | genres :  ['Crime|Film-Noir|Mystery'] | sim : tensor(0.8773, grad_fn=<DivBackward0>)\n",
      "movieId :  736  | title :  Twister (1996) | genres :  ['Action|Adventure|Romance|Thriller'] | sim : tensor(0.8704, grad_fn=<DivBackward0>)\n",
      "movieId :  354  | title :  Cobb (1994) | genres :  ['Drama'] | sim : tensor(0.8634, grad_fn=<DivBackward0>)\n",
      "movieId :  348  | title :  Bullets Over Broadway (1994) | genres :  ['Comedy'] | sim : tensor(0.8628, grad_fn=<DivBackward0>)\n",
      "movieId :  75  | title :  Big Bully (1996) | genres :  ['Comedy|Drama'] | sim : tensor(0.8573, grad_fn=<DivBackward0>)\n",
      "movieId :  346  | title :  Backbeat (1993) | genres :  ['Drama|Musical'] | sim : tensor(0.8565, grad_fn=<DivBackward0>)\n",
      "movieId :  537  | title :  Sirens (1994) | genres :  ['Drama'] | sim : tensor(0.8550, grad_fn=<DivBackward0>)\n",
      "movieId :  319  | title :  Shallow Grave (1994) | genres :  ['Comedy|Drama|Thriller'] | sim : tensor(0.8549, grad_fn=<DivBackward0>)\n",
      "movieId :  123  | title :  Chungking Express (Chung Hing sam lam) (1994) | genres :  ['Drama|Mystery|Romance'] | sim : tensor(0.8546, grad_fn=<DivBackward0>)\n",
      "movieId :  183  | title :  Mute Witness (1994) | genres :  ['Comedy|Horror|Thriller'] | sim : tensor(0.8541, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print(movie_embedding)\n",
    "result =dict()\n",
    "for embedded_movie in movie_embedding.keys():\n",
    "    cosine_sim = F.cosine_similarity(movie_embedding[embedded_movie], user_embedding_vector, dim = 0)\n",
    "    # print(embedded_movie, \" : \",cosine_sim)\n",
    "    result[embedded_movie] = cosine_sim\n",
    "\n",
    "result_recommend_list = sorted(result.items(), reverse=True, key=lambda item: item[1])\n",
    "# print(result_recommend_dict)\n",
    "# for i in result_recommend_dict:\n",
    "#     print(i[0])\n",
    "result_list_top_ten = list()\n",
    "result_list_top_ten_sim = list()\n",
    "result_recommend_list_top_ten = result_recommend_list[0:10]\n",
    "for i in result_recommend_list_top_ten:\n",
    "    result_list_top_ten.append(i[0])\n",
    "    result_list_top_ten_sim.append(i[1])\n",
    "# print(result_list_top_ten)\n",
    "# print(df_movies_real[df_movies_real['movieId'].isin(result_list_top_ten)])\n",
    "for ten in range (0,len(result_list_top_ten)):\n",
    "    one_thing_title = df_movies_real[df_movies_real['movieId'] == result_list_top_ten[ten]]['title'].values[0]\n",
    "    one_thing_genres = df_movies_real[df_movies_real['movieId'] == result_list_top_ten[ten]]['genres'].values\n",
    "    # print(ten,\" \", one_thing_title, \" \", one_thing_genres)\n",
    "    print(\"movieId : \",result_list_top_ten[ten], \" | title : \", one_thing_title, \"| genres : \",one_thing_genres,\"| sim :\", result_list_top_ten_sim[ten].item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 모르겠습니다. 죄송합니다. 부끄러운 말씀이지만, 무엇을 해야할 지에 대해서는 이해했습니다. 하지만 머신러닝을 위한 python 코드는 처음 짜는 것이기도 하고, 어떤 것이 좋은지도 전혀 알지 못하는 상황에서 이 과제를 해결하기에는 능력이 부족하다는 판단입니다. \n",
    "분명 오랜 시간을 투자했고, 여러모로 찾아봤지만 제 능력과 시간 내에서는 해결을 할 수 없다는 결론입니다.\n",
    "다음 과제가 나올지는 잘 모르겠으나, 다음에는 중간 과정마다 어떠한 결과가 나오는 것이 좋은 것일지 알려주실 수 있을까요? 이또한 무례한 것이라면 사과 드리겠으나, 머신러닝 코드 에 대한 이해가 부족한 저로서는 이것이 최소한의 요청일듯합니다. 죄송합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
