{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2: Movie recommendation\n",
    "\n",
    "- 과제 목표: 뉴럴 네트워크 모델을 설계한 후 모델을 학습하여 각 영화들의 embedding 들을 생성하고, 영화 embedding 을 활용하여 각 사용자에게 맞춤형 영화를 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice\n",
    "\n",
    "<br>\n",
    "\n",
    "- 과제를 수행하면서 각 task 마다 꼭 주어진 1개의 cell만을 사용할 필요는 없으며, 여러 개의 cell을 추가하여 자유롭게 사용해도 괜찮습니다.\n",
    "- 과제 수행을 위해 필요한 module이 있다면 추가로 import 해도 괜찮습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch # For building network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import permutations\n",
    "from itertools import permutations # For making pairs\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vidigummy/opt/anaconda3/envs/RS/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './MovieLens100K/'\n",
    "df_ratings = pd.read_csv(dir + 'ratings.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "df_movies_real = pd.read_csv(dir + 'movies.csv', usecols=['movieId', 'title', 'genres']) # for title-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 1 (3 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "1. df_ratings로 부터 각 사용자들이 본 영화를 기록.\n",
    "2. 사용자 마다 본 영화 목록을 $(movie1, movie2)$, $(movie2, movie1)$ 과 같이 pair로 생성.\n",
    "    - 즉, 각 사용자 마다 본 영화 목록에 대해 Permutation을 수행\n",
    "3. 2번 과정이 끝난 후, random을 이용해 각 pair 순서를 무작위로 shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating\n",
      "0           1        1     4.0\n",
      "1           1        3     4.0\n",
      "2           1        6     4.0\n",
      "3           1       47     5.0\n",
      "4           1       50     5.0\n",
      "...       ...      ...     ...\n",
      "99590     610      912     3.5\n",
      "99591     610      919     3.5\n",
      "99592     610      923     4.0\n",
      "99593     610      924     4.5\n",
      "99594     610      968     4.0\n",
      "\n",
      "[21667 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "df_users = df_ratings['userId'].drop_duplicates()\n",
    "movies_permutation_result = []\n",
    "df_movies = df_ratings['movieId'] < 1000\n",
    "df_movies_true = df_ratings[df_movies]\n",
    "print(df_movies_true)\n",
    "for i in df_users:\n",
    "    is_user_movies = df_movies_true['userId'] == i\n",
    "    user_movies = df_movies_true[is_user_movies]['movieId']\n",
    "    user_movies_list = user_movies.values.tolist()\n",
    "    user_movies_permutation = list(permutations(user_movies_list, 2))\n",
    "    movies_permutation_result.extend(user_movies_permutation)\n",
    "random.shuffle(movies_permutation_result)\n",
    "# print(len(movies_permutation_result))\n",
    "# print(movies_permutation_result)\n",
    "# print(len(movies_permutation_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train neural networks for generating movie embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 2 (4 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 각 영화 임베딩을 구하기 위해 뉴럴 네트워크 모델을 활용하여 multi-class classification 을 수행\n",
    "\n",
    "- 설계할 신경망의 기본 구조는 **Input Layer - Hidden(Embedding) Layer - Output Layer**.\n",
    "    - 7주차 강의자료 p.7 신경망 구조 이미지 참고\n",
    "\n",
    "- 현재 Network를 통해 하고자 하는 task는 multi-class classification.\n",
    "    - 예: $(movie1, movie2)$ 와 같은 입력 데이터와 정답 출력 데이터를 이용해 모델을 학습\n",
    "        - Input : $movie1$의 one-hot vector\n",
    "        - Output : $\\widehat{movie2}$의 one-hot vector\n",
    "        - Compute Loss : $\\widehat{movie2}$ 와 $movie2$ 간의 Cross-entropy Loss\n",
    "- 학습이 완료된 이후에 input layer와 hidden(embedding) layer 사이의 weight matrix $W_{in}$를 movie에 대한 embedding vector로 사용이 가능.\n",
    "> embedding size(# of hidden units)는 100 이하로 두는 것을 권장. <br>\n",
    "> embedding layer 다음 hidden layer를 더 추가하여 Genre와 같은 추가 정보를 학습에 활용 할 수도 있음 (필수적으로 고려해야할 사항은 아님).\n",
    "\n",
    "- 설계한 뉴럴 네트워크 모델의 학습이 완료된 후, 학습된 weight matrix $W_{in}$의 행/열벡터를 각 영화에 대한 embedding vector로 간주하여 영화 embedding 들을 구할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.embedded_layer = nn.Linear(input_size, 100)\n",
    "        self.hidden_layer = nn.Linear(100, 100)\n",
    "        self.output_layer = nn.Linear(100,input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x = self.embedded_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         movieId\n",
      "0            155\n",
      "1             72\n",
      "2            553\n",
      "3            508\n",
      "4            775\n",
      "...          ...\n",
      "1869541      920\n",
      "1869542      741\n",
      "1869543      587\n",
      "1869544      329\n",
      "1869545      973\n",
      "\n",
      "[1869546 rows x 1 columns]\n",
      "torch_one_hot_movie1 shape :  torch.Size([1869546, 761])\n",
      "Epoch    1/2 loss: 6.635469\n",
      "Epoch    2/2 loss: 6.366889\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "movies_pair_dataframe = pd.DataFrame(data= movies_permutation_result, columns=['movie1','movie2'])\n",
    "\n",
    "#영화의 개수를 가지고 one-hot vector로 만들어뿌자\n",
    "df_movie1 = pd.DataFrame(data=movies_pair_dataframe['movie1'].values,columns=['movieId'])\n",
    "print(df_movie1)\n",
    "df_movie2 = pd.DataFrame(data=movies_pair_dataframe['movie2'].values,columns=['movieId'])\n",
    "df_concat_movies = pd.concat([df_movie1,df_movie2],axis=0)\n",
    "df_one_hot_embedded = pd.get_dummies(data=df_concat_movies, columns = ['movieId'])\n",
    "df_one_hot_embedded_movie1 = df_one_hot_embedded.iloc[:int(df_one_hot_embedded.shape[0]/2), :]\n",
    "df_one_hot_embedded_movie2 = df_one_hot_embedded.iloc[int(df_one_hot_embedded.shape[0]/2):,:]\n",
    "#df로 만들었다. (1099200, 1859)로 자식들이 아주 건강하다.\n",
    "torch_one_hot_movie1 = torch.as_tensor(df_one_hot_embedded_movie1.values).float()\n",
    "torch_one_hot_movie2 = torch.as_tensor(df_one_hot_embedded_movie2.values).float()\n",
    "print(\"torch_one_hot_movie1 shape : \", torch_one_hot_movie1.shape)\n",
    "model = NnNetwork(torch_one_hot_movie1.shape[1])\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "# optimizer2 = torch.optim.Adam(model.parameters(),lr=0.1, betas = (0.9,0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer2 = torch.optim.Adam(model.parameters(),lr=0.1, betas = (0.9,0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "for epoch in range(2):\n",
    "    #make one-hot vector(input, target Generation)\n",
    "    output = model(torch_one_hot_movie1)\n",
    "    loss = loss_function(output, torch_one_hot_movie2)\n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "    # loss.backward()\n",
    "    print('Epoch {:4d}/{} loss: {:.6f}'.format(\n",
    "        epoch+1, 2, loss.item()\n",
    "    ))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n",
      "100\n",
      "155\n",
      "72\n",
      "553\n",
      "508\n",
      "775\n",
      "891\n",
      "594\n",
      "550\n",
      "780\n",
      "113\n",
      "34\n",
      "541\n",
      "10\n",
      "15\n",
      "610\n",
      "3\n",
      "940\n",
      "380\n",
      "262\n",
      "589\n",
      "780\n",
      "19\n",
      "595\n",
      "509\n",
      "420\n",
      "589\n",
      "368\n",
      "880\n",
      "318\n",
      "750\n",
      "778\n",
      "597\n",
      "543\n",
      "349\n",
      "599\n",
      "135\n",
      "339\n",
      "477\n",
      "333\n",
      "948\n",
      "784\n",
      "745\n",
      "736\n",
      "252\n",
      "242\n",
      "60\n",
      "374\n",
      "374\n",
      "553\n",
      "151\n",
      "533\n",
      "836\n",
      "362\n",
      "616\n",
      "234\n",
      "357\n",
      "938\n",
      "249\n",
      "786\n",
      "150\n",
      "583\n",
      "778\n",
      "235\n",
      "707\n",
      "842\n",
      "318\n",
      "164\n",
      "95\n",
      "247\n",
      "546\n",
      "370\n",
      "252\n",
      "16\n",
      "235\n",
      "97\n",
      "466\n",
      "897\n",
      "606\n",
      "590\n",
      "555\n",
      "918\n",
      "849\n",
      "522\n",
      "420\n",
      "575\n",
      "296\n",
      "425\n",
      "193\n",
      "266\n",
      "782\n",
      "316\n",
      "168\n",
      "858\n",
      "277\n",
      "474\n",
      "266\n",
      "344\n",
      "747\n",
      "412\n",
      "480\n",
      "714\n",
      "922\n",
      "10\n",
      "292\n",
      "480\n",
      "3\n",
      "357\n",
      "207\n",
      "36\n",
      "858\n",
      "213\n",
      "858\n",
      "661\n",
      "500\n",
      "555\n",
      "95\n",
      "457\n",
      "928\n",
      "24\n",
      "784\n",
      "158\n",
      "70\n",
      "733\n",
      "524\n",
      "186\n",
      "597\n",
      "105\n",
      "207\n",
      "500\n",
      "923\n",
      "198\n",
      "500\n",
      "435\n",
      "364\n",
      "370\n",
      "39\n",
      "457\n",
      "920\n",
      "708\n",
      "780\n",
      "348\n",
      "589\n",
      "247\n",
      "588\n",
      "1\n",
      "70\n",
      "356\n",
      "969\n",
      "500\n",
      "745\n",
      "588\n",
      "892\n",
      "158\n",
      "839\n",
      "230\n",
      "327\n",
      "53\n",
      "293\n",
      "867\n",
      "500\n",
      "778\n",
      "661\n",
      "733\n",
      "70\n",
      "454\n",
      "543\n",
      "261\n",
      "988\n",
      "318\n",
      "227\n",
      "829\n",
      "553\n",
      "314\n",
      "17\n",
      "188\n",
      "588\n",
      "520\n",
      "539\n",
      "541\n",
      "780\n",
      "628\n",
      "382\n",
      "587\n",
      "29\n",
      "810\n",
      "50\n",
      "520\n",
      "65\n",
      "410\n",
      "996\n",
      "185\n",
      "256\n",
      "370\n",
      "432\n",
      "155\n",
      "490\n",
      "564\n",
      "163\n",
      "455\n",
      "574\n",
      "595\n",
      "953\n",
      "169\n",
      "916\n",
      "858\n",
      "597\n",
      "50\n",
      "364\n",
      "151\n",
      "416\n",
      "349\n",
      "555\n",
      "708\n",
      "277\n",
      "60\n",
      "356\n",
      "153\n",
      "688\n",
      "193\n",
      "318\n",
      "508\n",
      "292\n",
      "908\n",
      "110\n",
      "358\n",
      "910\n",
      "481\n",
      "431\n",
      "25\n",
      "273\n",
      "39\n",
      "208\n",
      "254\n",
      "344\n",
      "380\n",
      "12\n",
      "172\n",
      "577\n",
      "293\n",
      "28\n",
      "32\n",
      "555\n",
      "837\n",
      "256\n",
      "32\n",
      "597\n",
      "780\n",
      "631\n",
      "663\n",
      "62\n",
      "261\n",
      "924\n",
      "95\n",
      "382\n",
      "377\n",
      "205\n",
      "628\n",
      "585\n",
      "595\n",
      "318\n",
      "592\n",
      "527\n",
      "165\n",
      "736\n",
      "344\n",
      "442\n",
      "419\n",
      "357\n",
      "457\n",
      "471\n",
      "785\n",
      "899\n",
      "590\n",
      "508\n",
      "540\n",
      "347\n",
      "788\n",
      "235\n",
      "798\n",
      "858\n",
      "380\n",
      "92\n",
      "809\n",
      "95\n",
      "608\n",
      "472\n",
      "911\n",
      "356\n",
      "231\n",
      "472\n",
      "315\n",
      "750\n",
      "407\n",
      "782\n",
      "153\n",
      "17\n",
      "175\n",
      "237\n",
      "141\n",
      "480\n",
      "915\n",
      "457\n",
      "225\n",
      "736\n",
      "837\n",
      "948\n",
      "784\n",
      "2\n",
      "185\n",
      "522\n",
      "1\n",
      "371\n",
      "762\n",
      "45\n",
      "181\n",
      "356\n",
      "543\n",
      "590\n",
      "300\n",
      "293\n",
      "986\n",
      "454\n",
      "24\n",
      "273\n",
      "41\n",
      "345\n",
      "480\n",
      "539\n",
      "912\n",
      "316\n",
      "19\n",
      "786\n",
      "380\n",
      "317\n",
      "266\n",
      "548\n",
      "188\n",
      "586\n",
      "180\n",
      "482\n",
      "955\n",
      "802\n",
      "480\n",
      "474\n",
      "161\n",
      "349\n",
      "340\n",
      "631\n",
      "661\n",
      "260\n",
      "47\n",
      "616\n",
      "247\n",
      "252\n",
      "575\n",
      "595\n",
      "181\n",
      "475\n",
      "788\n",
      "7\n",
      "852\n",
      "608\n",
      "640\n",
      "329\n",
      "261\n",
      "296\n",
      "515\n",
      "371\n",
      "372\n",
      "613\n",
      "830\n",
      "186\n",
      "911\n",
      "474\n",
      "708\n",
      "594\n",
      "3\n",
      "274\n",
      "185\n",
      "589\n",
      "65\n",
      "718\n",
      "737\n",
      "16\n",
      "231\n",
      "849\n",
      "64\n",
      "448\n",
      "719\n",
      "383\n",
      "140\n",
      "541\n",
      "440\n",
      "34\n",
      "609\n",
      "454\n",
      "919\n",
      "316\n",
      "442\n",
      "832\n",
      "356\n",
      "31\n",
      "520\n",
      "930\n",
      "442\n",
      "806\n",
      "858\n",
      "252\n",
      "588\n",
      "342\n",
      "170\n",
      "318\n",
      "784\n",
      "671\n",
      "905\n",
      "158\n",
      "364\n",
      "653\n",
      "372\n",
      "924\n",
      "141\n",
      "474\n",
      "329\n",
      "736\n",
      "207\n",
      "952\n",
      "110\n",
      "653\n",
      "62\n",
      "899\n",
      "307\n",
      "376\n",
      "593\n",
      "556\n",
      "480\n",
      "780\n",
      "239\n",
      "360\n",
      "648\n",
      "858\n",
      "736\n",
      "533\n",
      "781\n",
      "422\n",
      "208\n",
      "44\n",
      "594\n",
      "180\n",
      "367\n",
      "293\n",
      "349\n",
      "94\n",
      "23\n",
      "464\n",
      "48\n",
      "920\n",
      "466\n",
      "173\n",
      "592\n",
      "541\n",
      "339\n",
      "20\n",
      "104\n",
      "786\n",
      "1\n",
      "500\n",
      "21\n",
      "36\n",
      "11\n",
      "237\n",
      "161\n",
      "218\n",
      "2\n",
      "8\n",
      "356\n",
      "435\n",
      "968\n",
      "1\n",
      "333\n",
      "100\n",
      "533\n",
      "923\n",
      "229\n",
      "799\n",
      "364\n",
      "506\n",
      "364\n",
      "412\n",
      "333\n",
      "62\n",
      "593\n",
      "961\n",
      "919\n",
      "60\n",
      "981\n",
      "928\n",
      "446\n",
      "736\n",
      "141\n",
      "66\n",
      "552\n",
      "500\n",
      "318\n",
      "353\n",
      "303\n",
      "2\n",
      "87\n",
      "798\n",
      "318\n",
      "296\n",
      "432\n",
      "442\n",
      "594\n",
      "434\n",
      "480\n",
      "276\n",
      "708\n",
      "904\n",
      "151\n",
      "804\n",
      "708\n",
      "544\n",
      "80\n",
      "322\n",
      "246\n",
      "164\n",
      "527\n",
      "648\n",
      "594\n",
      "342\n",
      "32\n",
      "231\n",
      "924\n",
      "805\n",
      "555\n",
      "5\n",
      "235\n",
      "318\n",
      "6\n",
      "697\n",
      "262\n",
      "22\n",
      "2\n",
      "153\n",
      "733\n",
      "596\n",
      "514\n",
      "28\n",
      "214\n",
      "509\n",
      "337\n",
      "367\n",
      "866\n",
      "647\n",
      "588\n",
      "277\n",
      "351\n",
      "442\n",
      "111\n",
      "281\n",
      "303\n",
      "4\n",
      "942\n",
      "512\n",
      "318\n",
      "434\n",
      "667\n",
      "356\n",
      "637\n",
      "239\n",
      "671\n",
      "585\n",
      "928\n",
      "293\n",
      "253\n",
      "208\n",
      "432\n",
      "802\n",
      "613\n",
      "233\n",
      "593\n",
      "597\n",
      "17\n",
      "539\n",
      "104\n",
      "597\n",
      "595\n",
      "594\n",
      "661\n",
      "357\n",
      "292\n",
      "376\n",
      "356\n",
      "410\n",
      "300\n",
      "252\n",
      "25\n",
      "111\n",
      "252\n",
      "296\n",
      "915\n",
      "512\n",
      "11\n",
      "65\n",
      "371\n",
      "353\n",
      "535\n",
      "95\n",
      "932\n",
      "762\n",
      "608\n",
      "110\n",
      "50\n",
      "160\n",
      "539\n",
      "979\n",
      "457\n",
      "292\n",
      "356\n",
      "159\n",
      "842\n",
      "29\n",
      "366\n",
      "529\n",
      "597\n",
      "119\n",
      "965\n",
      "420\n",
      "231\n",
      "590\n",
      "338\n",
      "168\n",
      "356\n",
      "357\n",
      "262\n",
      "552\n",
      "527\n",
      "533\n",
      "256\n",
      "529\n",
      "479\n",
      "589\n",
      "295\n",
      "555\n",
      "234\n",
      "93\n",
      "552\n",
      "10\n",
      "596\n",
      "161\n",
      "953\n",
      "991\n",
      "6\n",
      "562\n",
      "356\n",
      "482\n",
      "16\n",
      "574\n",
      "648\n",
      "608\n",
      "257\n",
      "639\n",
      "351\n",
      "362\n",
      "39\n",
      "589\n",
      "553\n",
      "296\n",
      "158\n",
      "475\n",
      "261\n",
      "638\n",
      "662\n",
      "466\n",
      "953\n",
      "370\n",
      "26\n",
      "296\n",
      "608\n",
      "913\n",
      "22\n",
      "500\n",
      "552\n",
      "799\n",
      "851\n",
      "724\n",
      "810\n",
      "508\n",
      "908\n",
      "248\n",
      "367\n",
      "442\n",
      "61\n",
      "500\n",
      "339\n",
      "248\n",
      "594\n",
      "368\n",
      "466\n",
      "44\n",
      "7\n",
      "88\n",
      "166\n",
      "141\n",
      "588\n",
      "348\n",
      "849\n",
      "915\n",
      "390\n",
      "616\n",
      "208\n",
      "610\n",
      "5\n",
      "454\n",
      "172\n",
      "110\n",
      "450\n",
      "848\n",
      "216\n",
      "908\n",
      "153\n",
      "356\n",
      "158\n",
      "153\n",
      "986\n",
      "800\n",
      "780\n",
      "337\n",
      "585\n",
      "592\n",
      "150\n",
      "849\n",
      "613\n",
      "231\n",
      "541\n",
      "317\n",
      "292\n",
      "741\n",
      "230\n",
      "277\n",
      "788\n",
      "905\n",
      "628\n",
      "376\n",
      "586\n",
      "45\n",
      "39\n",
      "163\n",
      "10\n",
      "480\n",
      "412\n",
      "357\n",
      "949\n",
      "253\n",
      "1\n",
      "491\n",
      "733\n",
      "965\n",
      "2\n",
      "480\n",
      "317\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "movie_embedding = dict()\n",
    "cnt = 0\n",
    "# print(df_movie1)\n",
    "#761*100\n",
    "for param in model.named_parameters():\n",
    "    a = param[1]\n",
    "    print(len(a[0]))\n",
    "    print(len(a))\n",
    "    for i in range(len(a[0])):\n",
    "        # print(i)\n",
    "        # if(int(df_movie1.loc[i,'movieId']) == 70):\n",
    "        #     print(70)\n",
    "        print(int(df_movie1.loc[i,'movieId']))\n",
    "        movie_embedding[int(df_movie1.loc[i,'movieId'])] = a[:,i]\n",
    "    break\n",
    "print(len(movie_embedding))\n",
    "# print(movie_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend customized movies to user\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 3 (3 points)\n",
    "\n",
    "<br>\n",
    "\n",
    "- 임의의 한명의 사용자에 대하여 해당 사용자가 봤던 영화 n개에 대해 **통합된 embedding vector**를 생성.\n",
    "    - n개의 embedding vector들에 대해, element-wise한 계산을 통해 통합된 하나의 embedding vector를 생성.\n",
    "    - 이 embedding vector는 해당 사용자의 전반적인 영화 시청 성향을 나타내는 embedding vector로 간주할 수 있음.\n",
    "    - 즉, **사용자 1명 당 1개의 embedding vector**를 가짐.\n",
    "- 통합된 embedding vector와 학습된 weight matrix $W_{in}$의 모든 영화 embedding vector들 간의 유사도를 계산.\n",
    "- 그 중 유사도가 높은 (top n) 영화들을 선정, 사용자에게 추천.\n",
    "    > Recommended format : MovieId, Title, Genre, Similarity 가 포함된 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  has lost!\n",
      "157  has lost!\n",
      "223  has lost!\n",
      "423  has lost!\n",
      "441  has lost!\n",
      "673  has lost!\n",
      "943  has lost!\n",
      "954  has lost!\n",
      "41\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([-0.0206,  0.0352, -0.1359,  0.0833,  0.1099, -0.0077,  0.0744, -0.1205,\n",
      "        -0.0140,  0.0969, -0.0546, -0.0667, -0.0571,  0.0057,  0.0875,  0.0742,\n",
      "        -0.0125, -0.0564,  0.0116, -0.0933, -0.0158, -0.0058, -0.0882, -0.0444,\n",
      "         0.0015, -0.0168, -0.0282, -0.0143, -0.0361, -0.0097,  0.1060,  0.0812,\n",
      "         0.1279, -0.0011, -0.0555,  0.0878,  0.0882,  0.0146, -0.0280, -0.0411,\n",
      "        -0.0067,  0.0694, -0.0320,  0.0108,  0.0736,  0.1348,  0.0798,  0.0857,\n",
      "         0.0791,  0.1121,  0.0680,  0.1043,  0.0804,  0.1139, -0.0680, -0.0567,\n",
      "         0.0878,  0.0977,  0.1008, -0.1015,  0.1363,  0.1332,  0.1341,  0.0085,\n",
      "        -0.0018, -0.0787,  0.0868,  0.0692, -0.0607, -0.0621, -0.0356, -0.0162,\n",
      "         0.0990,  0.0760, -0.1208,  0.0803,  0.0988, -0.1078, -0.1112, -0.0742,\n",
      "        -0.0395, -0.0297,  0.0805, -0.0454,  0.1044,  0.0788,  0.0006, -0.0117,\n",
      "         0.1031,  0.1127,  0.0936, -0.0648,  0.0254,  0.0982,  0.0913,  0.0864,\n",
      "         0.0770,  0.0771,  0.0804,  0.1502], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#### Your Code Here\n",
    "is_user_movies = df_movies_true['userId'] == 1\n",
    "users_movies = df_movies_true[is_user_movies]\n",
    "user_movies = users_movies['movieId']\n",
    "# print(user_movies.shape)\n",
    "user_movie_dict =dict()\n",
    "# print(df_movie1[df_movie1['movieId'] == 157])\n",
    "# for movie in movie_embedding:\n",
    "#     print(movie)\n",
    "for movieId in user_movies:\n",
    "    # print(movie_embedding[movieId])\n",
    "    try:\n",
    "        user_movie_dict[movieId] = movie_embedding[movieId]\n",
    "    except:\n",
    "        print(movieId , \" has lost!\")\n",
    "# print(user_movie_dict)\n",
    "print(len(user_movie_dict))\n",
    "user_embedding_vector = torch.zeros(100)\n",
    "print(user_embedding_vector)\n",
    "for i in user_movie_dict.keys():\n",
    "    # print(len(i_list))\n",
    "    i_list = user_movie_dict[i]/len(user_movie_dict)\n",
    "    for j in range(0,len(i_list)):\n",
    "        user_embedding_vector[j] += i_list[j]\n",
    "\n",
    "#유저 임베딩 벡터 완성(이게 맞나...)\n",
    "print(user_embedding_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId :  736  | title :  Twister (1996) | genres :  ['Action|Adventure|Romance|Thriller'] | sim : 0.8748392462730408\n",
      "movieId :  905  | title :  It Happened One Night (1934) | genres :  ['Comedy|Romance'] | sim : 0.8631466031074524\n",
      "movieId :  918  | title :  Meet Me in St. Louis (1944) | genres :  ['Musical'] | sim : 0.8585366010665894\n",
      "movieId :  968  | title :  Night of the Living Dead (1968) | genres :  ['Horror|Sci-Fi|Thriller'] | sim : 0.8440254926681519\n",
      "movieId :  70  | title :  From Dusk Till Dawn (1996) | genres :  ['Action|Comedy|Horror|Thriller'] | sim : 0.8412495255470276\n",
      "movieId :  422  | title :  Blink (1994) | genres :  ['Thriller'] | sim : 0.8407755494117737\n",
      "movieId :  135  | title :  Down Periscope (1996) | genres :  ['Comedy'] | sim : 0.8376667499542236\n",
      "movieId :  218  | title :  Boys on the Side (1995) | genres :  ['Comedy|Drama'] | sim : 0.8374474048614502\n",
      "movieId :  491  | title :  Man Without a Face, The (1993) | genres :  ['Drama'] | sim : 0.8355104327201843\n",
      "movieId :  88  | title :  Black Sheep (1996) | genres :  ['Comedy'] | sim : 0.8281322717666626\n"
     ]
    }
   ],
   "source": [
    "# print(movie_embedding)\n",
    "result =dict()\n",
    "for embedded_movie in movie_embedding.keys():\n",
    "    cosine_sim = F.cosine_similarity(movie_embedding[embedded_movie], user_embedding_vector, dim = 0)\n",
    "    # print(embedded_movie, \" : \",cosine_sim)\n",
    "    result[embedded_movie] = cosine_sim\n",
    "\n",
    "result_recommend_list = sorted(result.items(), reverse=True, key=lambda item: item[1])\n",
    "# print(result_recommend_dict)\n",
    "# for i in result_recommend_dict:\n",
    "#     print(i[0])\n",
    "result_list_top_ten = list()\n",
    "result_list_top_ten_sim = list()\n",
    "result_recommend_list_top_ten = result_recommend_list[0:10]\n",
    "for i in result_recommend_list_top_ten:\n",
    "    result_list_top_ten.append(i[0])\n",
    "    result_list_top_ten_sim.append(i[1])\n",
    "# print(result_list_top_ten)\n",
    "# print(df_movies_real[df_movies_real['movieId'].isin(result_list_top_ten)])\n",
    "for ten in range (0,len(result_list_top_ten)):\n",
    "    one_thing_title = df_movies_real[df_movies_real['movieId'] == result_list_top_ten[ten]]['title'].values[0]\n",
    "    one_thing_genres = df_movies_real[df_movies_real['movieId'] == result_list_top_ten[ten]]['genres'].values\n",
    "    # print(ten,\" \", one_thing_title, \" \", one_thing_genres)\n",
    "    print(\"movieId : \",result_list_top_ten[ten], \" | title : \", one_thing_title, \"| genres : \",one_thing_genres,\"| sim :\", result_list_top_ten_sim[ten].item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 모르겠습니다. 죄송합니다. 부끄러운 말씀이지만, 무엇을 해야할 지에 대해서는 이해했습니다. 하지만 머신러닝을 위한 python 코드는 처음 짜는 것이기도 하고, 어떤 것이 좋은지도 전혀 알지 못하는 상황에서 이 과제를 해결하기에는 능력이 부족하다는 판단입니다. \n",
    "분명 오랜 시간을 투자했고, 여러모로 찾아봤지만 제 능력과 시간 내에서는 해결을 할 수 없다는 결론입니다.\n",
    "다음 과제가 나올지는 잘 모르겠으나, 다음에는 중간 과정마다 어떠한 결과가 나오는 것이 좋은 것일지 알려주실 수 있을까요? 이또한 무례한 것이라면 사과 드리겠으나, 머신러닝 코드 에 대한 이해가 부족한 저로서는 이것이 최소한의 요청일듯합니다. 죄송합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
