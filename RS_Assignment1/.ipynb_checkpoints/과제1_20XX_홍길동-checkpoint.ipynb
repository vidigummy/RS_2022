{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Modules\n",
    "\n",
    "<br>\n",
    "\n",
    "- matplotlib >= 3.1.1\n",
    "- mplcursors >= 0.5.1\n",
    "    - use command to install(in notebook) : **!pip install mplcursors**\n",
    "- numpy >= 1.21.5\n",
    "- pandas >= 0.25.1\n",
    "- sklearn >= 0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: numpy in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: pandas in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: sklearn in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/vidigummy/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors # Use this is for creating a cursor-interactive plot with \"%matplotlib notebook\"\n",
    "from sklearn.decomposition import NMF # Use this for training Non-negative Matrix Factorization\n",
    "from sklearn.utils.extmath import randomized_svd # Use this for training Singular Value Decomposition\n",
    "from sklearn.manifold import TSNE # Use this for training t-sne manifolding\n",
    "\n",
    "plt.style.use('ggplot') # You can also use different style\n",
    "\n",
    "# just for plot checking, use this option\n",
    "# %matplotlib inline\n",
    "\n",
    "# for interactive plot\n",
    "# If you use this option, plot will appear at first-drawn position\n",
    "%matplotlib notebook\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### File description : MovieLens-100K\n",
    "- movies.csv : list of movies (9742 movies)\n",
    "- ratings.csv : list of ratings given by users (610 users, 100,836 ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './MovieLens100K/'\n",
    "df_ratings = pd.read_csv(dir + 'ratings.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "df_movies = pd.read_csv(dir + 'movies.csv', usecols=['movieId', 'title', 'genres']) # for title-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple EDA (Exploratory Data Analysis)\n",
    "\n",
    "<br>\n",
    "\n",
    "- Before starting, let's perform simple data analysis on the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고유 사용자, 고유 영화 갯수 확인\n",
    "n_users = len(df_ratings['userId'].unique())\n",
    "n_movies = len(df_ratings['movieId'].unique())\n",
    "\n",
    "n_users, n_movies # 610 명의 사용자가 9724개의 영화에 평점을 매김을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_movies) # len(df_movies) - n_movies 만큼의 평점이 매겨지지 않은 영화가 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100836.000000\n",
       "mean          3.501557\n",
       "std           1.042529\n",
       "min           0.500000\n",
       "25%           3.000000\n",
       "50%           3.500000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratings의 기술통계량 확인\n",
    "df_ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Utility Matrix $A$\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 1 (2 points)\n",
    "1. Generate an utility matrix $A$ by using **df_ratings** (store rating values with unique 'movieId' and 'userId')\n",
    "2. Within a matrix $A$, replace NaN values (unknown ratings) with 0 (zero value)\n",
    "3. Convert the utility matrix $A$ to **numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating\n",
      "0            1        1     4.0\n",
      "1            1        3     4.0\n",
      "2            1        6     4.0\n",
      "3            1       47     5.0\n",
      "4            1       50     5.0\n",
      "...        ...      ...     ...\n",
      "100831     610   166534     4.0\n",
      "100832     610   168248     5.0\n",
      "100833     610   168250     5.0\n",
      "100834     610   168252     5.0\n",
      "100835     610   170875     3.0\n",
      "\n",
      "[100836 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100836, 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Utility Matrix의 형태는 (n_movies, n_users)\n",
    "# 즉 Utility Matrix 의 각 행은 movie, 각 열은 user를 나타냄\n",
    "\"\"\"\n",
    "# your code here\n",
    "tmp = df_ratings[['userId','movieId']]\n",
    "A = tmp.replace(np.NaN, 0)\n",
    "# 올바른 형태로 utility matrix가 생성되었는지 확인\n",
    "print(A.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVD Model\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 2 (2 points)\n",
    "1. Decompose utility matrix $A$ into three matrices $U$, $\\sum$, and $V^T$ by training SVD model (you can use  randomized_svd() function provided from scikit-learn)\n",
    "    - Refer to: https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_svd.html\n",
    "\n",
    "2. After training SVD is completed, perform dot-product of $U$, $\\sum$, and $V^T$ to obtain the matrix $A_{approx_{svd}}$ that approximates matrix $A$\n",
    "    - Note that, **$\\sum$ should be a diagonal matrix**, not a vector\n",
    "    - Before computing $A_{approx_{svd}}$, you will need to transform $\\sum$ generated from randomized_svd() to a diagonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# sklearn에서 제공하는 randomized_svd()를 통해 SVD 모델을 학습하여 U, Sigma, VT를 구함\n",
    "# k는 분해될 행렬들의 feature/factor 의 크기를 정하는 hyperparameter\n",
    "# 여러 인자를 조정해서 randomized_svd()를 실행 가능 (자세한 내용은 위의 참고 사이트를 참고)\n",
    "# 분해된 행렬 U, Sigma, VT의 형태는 (n_movies, k), (k,) (k, n_users)\n",
    "# 분해된 행렬들을 이용하여 dot-product 연산을 수행하면 원래의 utility matrix와 같은 (n_movies, n_users) 형태의 근사 행렬을 얻을 수 있음\n",
    "\"\"\"\n",
    "\n",
    "# your code here\n",
    "\n",
    "k =\n",
    "U, Sigma, VT = \n",
    "\n",
    "# 분해된 행렬이 올바른 형태로 생성되었는지 확인\n",
    "print(U.shape, Sigma.shape, VT.shape)\n",
    "\n",
    "A_approx_svd =\n",
    "\n",
    "# 근사 행렬이 올바른 형태로 생성되었는지 확인\n",
    "print(A_approx_svd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NMF Model\n",
    "\n",
    "<br>\n",
    "\n",
    "> ### Problem 3 (2 points)\n",
    "1. Decompose utility matrix $A$ into two matrices $W$ and $H$ by training NMF model (using NMF()).\n",
    "    - Refer to: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF\n",
    "\n",
    "2. After training NMF, perform dot-product of $W$ and $H$ to obtain the matrix $A_{approx_{nmf}}$ that approximates matrix $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# sklearn에서 제공하는 NMF()를 통해 NMF 모델을 학습하여 W, H를 구함\n",
    "# SVD와 마찬가지로, k는 분해될 행렬들의 feature/factor 의 크기를 정하는 hyperparameter\n",
    "# 여러 인자를 조정해서 NMF() 모델을 생성 (자세한 내용은 위의 참고 사이트를 참고)\n",
    "# 분해된 행렬 W와 H는 .fit(data)를 실행한 후에 구할수 있으며, W와 H의 형태는 (n_movies, k), (k, n_users)\n",
    "# 분해된 행렬들을 이용하여 dot-product 연산을 수행하면 원래의 utility matrix와 같은 (n_movies, n_users) 형태의 근사 행렬을 구할 수 있음\n",
    "\"\"\"\n",
    "\n",
    "# your code here\n",
    "\n",
    "k = \n",
    "model_nmf = \n",
    "W = \n",
    "H = \n",
    "\n",
    "# 분해된 행렬이 올바른 형태로 생성되었는지 확인\n",
    "print(W.shape, H.shape)\n",
    "\n",
    "A_approx_nmf = \n",
    "\n",
    "# 근사 행렬이 올바른 형태로 생성되었는지 확인\n",
    "print(A_approx_nmf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute loss by implementing a custom function\n",
    "\n",
    "> ### Problem 4 (2 points)\n",
    "1. Implement **compute_error(actual, prediction)** function that takes matrices 'actual' and 'prediction' as input parameters.\n",
    "    1. Ignore zero values in the actual maxtrix\n",
    "    2. Compute SSE and RMSE\n",
    "    3. Return SSE and RMSE\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Implement **compute_error_all(actual, prediction)** function that takes matrices 'actual' and 'prediction' as input parameters.\n",
    "    1. Do not ignore zero values in the actual matrix (compute all values)\n",
    "    2. Compute SSE and RMSE\n",
    "    3. Return SSE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 실제 utility matrix A와 SVD 를 통해 생성된 행렬 A_approx_svd 간의 오차를 계산\n",
    "# 실제 utility matrix A와 NMF 를 통해 생성된 행렬 A_approx_nmf 간의 오차를 계산\n",
    "# 오차 값을 계산하기 위해 함수 compute_error(actual, prediction)와 compute_error_all(actual, prediction)를 구현\n",
    "# 강의시간에 배운 수식을 통해 함수 구현\n",
    "\"\"\"\n",
    "\n",
    "# your code here\n",
    "\n",
    "def compute_error(actual, prediction):\n",
    "    # 매개변수로 입력받은 actual 행렬 안의 0값을 갖는 원소들은 오차 계산에서 제외합니다.\n",
    "    prediction = \n",
    "    actual = \n",
    "    \n",
    "    sse = \n",
    "    rmse = \n",
    "    \n",
    "    return sse, rmse\n",
    "\n",
    "def compute_error_all(actual, prediction):\n",
    "    # actual 행렬 안의 0값을 갖는 원소들도 포함해서 오차를 계산합니다.\n",
    "    sse = \n",
    "    rmse = \n",
    "    \n",
    "    return sse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SVD Error(ignoring zero values): SSE = {compute_error(A, A_approx_svd)[0]}, RMSE = {compute_error(A, A_approx_svd)[1]}\")\n",
    "print(f\"NMF Error(ignoring zero values): SSE = {compute_error(A, A_approx_nmf)[0]}, RMSE = {compute_error(A, A_approx_nmf)[1]}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f\"SVD Error(including all zero values): SSE = {compute_error_all(A, A_approx_svd)[0]}, RMSE = {compute_error_all(A, A_approx_svd)[1]}\")\n",
    "print(f\"NMF Error(including all zero values): SSE = {compute_error_all(A, A_approx_nmf)[0]}, RMSE = {compute_error_all(A, A_approx_nmf)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict missing (unknown) values in utility matrix $A$ for a specific user\n",
    "\n",
    "\n",
    "> ### Problem 5 (2 points)\n",
    "\n",
    "- 실제 평점과 예측 평점을 확인할 수 있는 dataframe 생성을 위해 makePredictions(actual, pred, user) 함수를 정의\n",
    "- makePredictions() 함수는 user(사용자 번호, user index)를 통해 actual, pred에서 rated movies(seen movies), non-rated movies(unseen movies)를 추출\n",
    "- 그 다음 앞서 정의했던 df_movies와 추출한 2개의 dataframe을 concat 해줄 것\n",
    "- column mismatching이 일어날 수 있는데, 우선 dataframe을 모든 column과 concat한 후 불필요한 'movieId' column을 drop 해줄 것\n",
    "- 이어서 실제로 본 영화 목록을 rated_movies로 정의하고, rating을 기준으로 내림차순 정렬 수행\n",
    "- 마찬가지로 평점이 부여되지 않은 영화들(평점을 예측하고자하는 영화들)의 목록을 unrated_movies로 정의하고, dataframe의 index를 기준으로 오름차순 정렬 수행\n",
    "\n",
    "- dataframe의 앞, 뒤를 보는 함수는 .head(), .tail()를 사용할 수 있지만, 중간을 볼 수 있는 함수는 존재하지 않음\n",
    "- 따라서, 함수 findMiddle(dataframe)을 정의하고, 이 함수는 indexing을 통해 dataframe의 중간 위치를 보여줌\n",
    "- findMiddle()의 return은 dataframe의 중간 10개 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def makePredictions(actual, pred, user):\n",
    "    # rated_movies, unrated_movies 생성을 하기 위한 사전작업 dataframe을 정의할 수 있습니다. (약 4~5줄)\n",
    "    \n",
    "    # 실제로 본 영화 목록 (평점이 부여된 영화 목록)\n",
    "    rated_movies =\n",
    "    \n",
    "    \n",
    "    # 예측할 영화 목록 (평점이 부여되지 않은 영화 목록)\n",
    "    unrated_movies =\n",
    "    \n",
    "    \n",
    "    return rated_movies, unrated_movies\n",
    "\n",
    "\n",
    "def findMiddle(dataframe):\n",
    "    # dataframe의 중간 부분을 반환하는 함수입니다.\n",
    "    # return은 dataframe의 중간 10개 부분들 입니다. (dataframe 형식)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 임의의 사용자를 1명 선정하고, 앞서 작성한 함수에 svd, nmf의 근사 행렬을 인자로 전달\n",
    "\"\"\"\n",
    "\n",
    "# your code here\n",
    "\n",
    "# 임의의 사용자 (정수)를 선택\n",
    "userNumber = 10\n",
    "\n",
    "prediction_with_rated_svd, prediction_with_unrated_svd = makePredictions(A, A_approx_svd, userNumber) # 실제 Utility Matrix와 svd를 통해 근사한 행렬 간의 비교\n",
    "prediction_with_rated_nmf, prediction_with_unrated_nmf = makePredictions(A, A_approx_nmf, userNumber) # 실제 Utility Matrix와 nmf를 통해 근사한 행렬 간의 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_rated_svd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_rated_nmf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_unrated_svd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_unrated_nmf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_unrated_svd.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_with_unrated_nmf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findMiddle(prediction_with_unrated_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findMiddle(prediction_with_unrated_nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize movie embeddings using T-SNE\n",
    "\n",
    "\n",
    "> ### Extra Credit (2 points)\n",
    "\n",
    "- NMF에서 분해되어 나온 행렬 W는 movie에 대한 잠재 표현(latent representation)을 갖고 있음\n",
    "    - 마찬가지로, SVD에서 분해되어 나온 행렬 U도 movie에 대한 잠재 표현을 가짐\n",
    "- 잠재 공간에서 실제 영화들이 NMF를 통해 어떻게 임베딩 되었는지 2차원 상으로 변환해 확인할 수 있으며, 대표적인 방법으로 t-sne을 사용할 수 있음\n",
    "- 여러 인자를 조정해서 TSNE() 모델을 생성 가능 (자세한 내용은 공식 아래 사이트 참고)\n",
    "    - t-sne 참고 사이트: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "    - t-sne 학습 과정에 시간이 다소 소요될 수 있음\n",
    "- t-sne에서 fit()된 결과를 W_embedded에 저장\n",
    "- W_embedded.embedding_ 으로 변환된 임베딩 결과물을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "model_tsne = \n",
    "W_embedded = \n",
    "\n",
    "# 실제 2차원으로 변환되었는지 확인\n",
    "# 변환된 결과는 (n_movies, 2)의 형태\n",
    "print(W_embedded.embedding_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot하기 위해 각 영화 임베딩과 movie dataframe(df_movies)을 결합\n",
    "- 하지만 위 EDA에서 알 수 있듯이, movie.csv(df_movies)엔 사용자들이 평점을 매기지 않은 영화들이 존재함\n",
    "- 따라서, 임베딩과 각 영화의 index를 맞추기 위한 작업이 필요함\n",
    "\n",
    "- 먼저, numpy array로 변환 안된 (즉 dataframe 형태인) Utility matrix를 load하고, index들을 list로 추출\n",
    "- df_movies에서 'movieId'가 추출한 list에 있는 경우만을 추출 (그러면 이제 df_movies엔 평점이 매겨진 영화들만이 남게 됨)\n",
    "\n",
    "- (주의! 이때 reset_index(drop=True) 옵션을 사용해줘야 임베딩과 df_movies를 올바르게 결합할 수 있음)\n",
    "- (그렇지 않으면 index-mismatching이 발생해 NaN값이 생성됨)\n",
    "\n",
    "- 추출된 내용을 movie_with_embedding에 대입\n",
    "- movie_with_embedding의 각 끝 열에 앞서 구한 임베딩을 열로 추가\n",
    "- embedding은 (n_movies, 2)의 형태이므로, 각 column을 1개씩 'tsne1', 'tsne2'로써 movie_with_embedding의 column으로 추가\n",
    "- 삽입 시, 형태를 맞추기 위해선 .reshape() method가 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# 앞서 정의헀던 Utility Matrix와 동일한 방법으로 A2를 정의 (numpy array로 변환할 필요 없음)\n",
    "A2 = \n",
    "\n",
    "# allList엔 A2의 index 값(즉, movieId)들을 list로 변환한 내용이 들어있음\n",
    "allList =\n",
    "\n",
    "# movie_with_embedding은 df_movies에서 allList와 일치하는 부분만을 가지게 됨\n",
    "# movie_with_embedding에 'tsne1', 'tsne2' column을 추가 (추가하는 내용은 각각 임베딩의 첫번째 column, 두번째 column)\n",
    "movie_with_embedding = \n",
    "movie_with_embedding['tsne1'] = \n",
    "movie_with_embedding['tsne2'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종적으로 Plotting을 위해 생성한 dataframe이 어떤 모습으로 생겼는지 확인\n",
    "# 이때, dataframe에 NaN값이 있어서는 안됨\n",
    "movie_with_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tsne1, tsne2를 통해 scatter plot을 그릴 것\n",
    "- 'mplcursors'를 통해 각 point마다 확인하고 싶은 정보를 labelling 해줄 것\n",
    "- 이 기능을 사용하게 되면 point마다 text를 plot해줄 필요가 없고, 마우스 커서 클릭으로 point의 정보를 볼 수 있음\n",
    "- 상단 예시 코드에서 YOUR_ANNOTATION_LIST를 적절히 선택해 각 point마다의 제목 또는 장르를 확인할 수 있음\n",
    "- 이 함수를 사용하기 위해서는 '%matplotlib notebook' 이 필요함\n",
    "\n",
    "```python\n",
    "mplcursors.cursor(multiple = True).connect(\n",
    "    \"add\", lambda sel: sel.annotation.set_text(\n",
    "          YOUR_ANNOTATION_LIST[sel.target.index]\n",
    "))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10] # you can change size for your style\n",
    "plt.xlim(movie_with_embedding['tsne1'].min(), movie_with_embedding['tsne1'].max()) # 축 범위 조정\n",
    "plt.ylim(movie_with_embedding['tsne2'].min(), movie_with_embedding['tsne2'].max()) # 축 범위 조정\n",
    "\n",
    "# your code here\n",
    "\n",
    "# Scatter plot을 그리기\n",
    "\n",
    "\n",
    "# 위의 mplcursors 코드를 이용해 각 point마다 labelling을 할 수 있습니다.\n",
    "# YOUR_ANNOTATION_LIST는 영화 제목이 되어도 좋고, 영화 장르가 되어도 좋습니다.\n",
    "# (직관성을 위해 '영화장르'로 labelling 하는 것을 추천합니다.)\n",
    "\n",
    "plt.title('t-sne result (visualization of movie embeddings)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
